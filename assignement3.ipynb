{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef94525f",
   "metadata": {},
   "source": [
    "# Assignment 3: Agentic RAG System with Azure OpenAI & LangGraph\n",
    "\n",
    "## 1. Setup & Installation\n",
    "Install required packages for Azure OpenAI, LangGraph, Pinecone/Weaviate, MLflow, and data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be6e6e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in ./genai/lib/python3.12/site-packages (0.6.6)\n",
      "Requirement already satisfied: azure-ai-inference in ./genai/lib/python3.12/site-packages (1.0.0b9)\n",
      "Requirement already satisfied: pinecone in ./genai/lib/python3.12/site-packages (7.3.0)\n",
      "Requirement already satisfied: mlflow in ./genai/lib/python3.12/site-packages (3.3.2)\n",
      "Requirement already satisfied: pydantic in ./genai/lib/python3.12/site-packages (2.11.7)\n",
      "Requirement already satisfied: langchain-core>=0.1 in ./genai/lib/python3.12/site-packages (from langgraph) (0.3.74)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in ./genai/lib/python3.12/site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in ./genai/lib/python3.12/site-packages (from langgraph) (0.6.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in ./genai/lib/python3.12/site-packages (from langgraph) (0.2.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./genai/lib/python3.12/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./genai/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./genai/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./genai/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.2)\n",
      "Requirement already satisfied: isodate>=0.6.1 in ./genai/lib/python3.12/site-packages (from azure-ai-inference) (0.7.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in ./genai/lib/python3.12/site-packages (from azure-ai-inference) (1.35.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./genai/lib/python3.12/site-packages (from azure-ai-inference) (4.15.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in ./genai/lib/python3.12/site-packages (from pinecone) (2025.8.3)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in ./genai/lib/python3.12/site-packages (from pinecone) (1.8.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in ./genai/lib/python3.12/site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./genai/lib/python3.12/site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in ./genai/lib/python3.12/site-packages (from pinecone) (2.5.0)\n",
      "Requirement already satisfied: packaging<25.0,>=24.2 in ./genai/lib/python3.12/site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in ./genai/lib/python3.12/site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./genai/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./genai/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.10)\n",
      "Requirement already satisfied: mlflow-skinny==3.3.2 in ./genai/lib/python3.12/site-packages (from mlflow) (3.3.2)\n",
      "Requirement already satisfied: mlflow-tracing==3.3.2 in ./genai/lib/python3.12/site-packages (from mlflow) (3.3.2)\n",
      "Requirement already satisfied: Flask<4 in ./genai/lib/python3.12/site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in ./genai/lib/python3.12/site-packages (from mlflow) (1.16.4)\n",
      "Requirement already satisfied: cryptography<46,>=43.0.0 in ./genai/lib/python3.12/site-packages (from mlflow) (45.0.6)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in ./genai/lib/python3.12/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in ./genai/lib/python3.12/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in ./genai/lib/python3.12/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: matplotlib<4 in ./genai/lib/python3.12/site-packages (from mlflow) (3.10.5)\n",
      "Requirement already satisfied: numpy<3 in ./genai/lib/python3.12/site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in ./genai/lib/python3.12/site-packages (from mlflow) (2.3.2)\n",
      "Requirement already satisfied: pyarrow<22,>=4.0.0 in ./genai/lib/python3.12/site-packages (from mlflow) (19.0.1)\n",
      "Requirement already satisfied: scikit-learn<2 in ./genai/lib/python3.12/site-packages (from mlflow) (1.7.1)\n",
      "Requirement already satisfied: scipy<2 in ./genai/lib/python3.12/site-packages (from mlflow) (1.13.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in ./genai/lib/python3.12/site-packages (from mlflow) (2.0.43)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in ./genai/lib/python3.12/site-packages (from mlflow-skinny==3.3.2->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./genai/lib/python3.12/site-packages (from mlflow-skinny==3.3.2->mlflow) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle<4 in ./genai/lib/python3.12/site-packages (from mlflow-skinny==3.3.2->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in ./genai/lib/python3.12/site-packages (from mlflow-skinny==3.3.2->mlflow) (0.64.0)\n",
      "Requirement already satisfied: fastapi<1 in ./genai/lib/python3.12/site-packages (from mlflow-skinny==3.3.2->mlflow) (0.116.1)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in ./genai/lib/python3.12/site-packages (from mlflow-skinny==3.3.2->mlflow) (3.1.45)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in ./genai/lib/python3.12/site-packages (from mlflow-skinny==3.3.2->mlflow) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in ./genai/lib/python3.12/site-packages (from mlflow-skinny==3.3.2->mlflow) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in ./genai/lib/python3.12/site-packages (from mlflow-skinny==3.3.2->mlflow) (1.36.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in ./genai/lib/python3.12/site-packages (from mlflow-skinny==3.3.2->mlflow) (6.32.0)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in ./genai/lib/python3.12/site-packages (from mlflow-skinny==3.3.2->mlflow) (6.0.2)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in ./genai/lib/python3.12/site-packages (from mlflow-skinny==3.3.2->mlflow) (0.5.3)\n",
      "Requirement already satisfied: uvicorn<1 in ./genai/lib/python3.12/site-packages (from mlflow-skinny==3.3.2->mlflow) (0.35.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./genai/lib/python3.12/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./genai/lib/python3.12/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./genai/lib/python3.12/site-packages (from pydantic) (0.4.1)\n",
      "Requirement already satisfied: Mako in ./genai/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: cffi>=1.14 in ./genai/lib/python3.12/site-packages (from cryptography<46,>=43.0.0->mlflow) (1.17.1)\n",
      "Requirement already satisfied: google-auth~=2.0 in ./genai/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (2.40.3)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in ./genai/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.3.2->mlflow) (0.47.3)\n",
      "Requirement already satisfied: blinker>=1.9.0 in ./genai/lib/python3.12/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in ./genai/lib/python3.12/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in ./genai/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./genai/lib/python3.12/site-packages (from Flask<4->mlflow) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in ./genai/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./genai/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.3.2->mlflow) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./genai/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.3.2->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./genai/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./genai/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in ./genai/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in ./genai/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in ./genai/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.3.2->mlflow) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./genai/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./genai/lib/python3.12/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./genai/lib/python3.12/site-packages (from matplotlib<4->mlflow) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./genai/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./genai/lib/python3.12/site-packages (from matplotlib<4->mlflow) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./genai/lib/python3.12/site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in ./genai/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.3.2->mlflow) (0.57b0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./genai/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./genai/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./genai/lib/python3.12/site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./genai/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./genai/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./genai/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: greenlet>=1 in ./genai/lib/python3.12/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in ./genai/lib/python3.12/site-packages (from starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.3.2->mlflow) (4.10.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./genai/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.3.2->mlflow) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in ./genai/lib/python3.12/site-packages (from uvicorn<1->mlflow-skinny==3.3.2->mlflow) (0.16.0)\n",
      "Requirement already satisfied: pycparser in ./genai/lib/python3.12/site-packages (from cffi>=1.14->cryptography<46,>=43.0.0->mlflow) (2.22)\n",
      "Requirement already satisfied: httpcore==1.* in ./genai/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in ./genai/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (0.4.17)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./genai/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./genai/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./genai/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./genai/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./genai/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.24.0)\n",
      "Requirement already satisfied: langchain_openai in ./genai/lib/python3.12/site-packages (0.3.31)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.74 in ./genai/lib/python3.12/site-packages (from langchain_openai) (0.3.74)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in ./genai/lib/python3.12/site-packages (from langchain_openai) (1.107.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./genai/lib/python3.12/site-packages (from langchain_openai) (0.11.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in ./genai/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.4.17)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./genai/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./genai/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./genai/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./genai/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in ./genai/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./genai/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./genai/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.74->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./genai/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./genai/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./genai/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./genai/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./genai/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./genai/lib/python3.12/site-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./genai/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain_openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./genai/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain_openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./genai/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./genai/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./genai/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./genai/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain_openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./genai/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./genai/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2025.7.34)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./genai/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.5)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./genai/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./genai/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./genai/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.24.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./genai/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./genai/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.5.0)\n",
      "Requirement already satisfied: pinecone in ./genai/lib/python3.12/site-packages (7.3.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in ./genai/lib/python3.12/site-packages (from pinecone) (2025.8.3)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in ./genai/lib/python3.12/site-packages (from pinecone) (1.8.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in ./genai/lib/python3.12/site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./genai/lib/python3.12/site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in ./genai/lib/python3.12/site-packages (from pinecone) (4.15.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in ./genai/lib/python3.12/site-packages (from pinecone) (2.5.0)\n",
      "Requirement already satisfied: packaging<25.0,>=24.2 in ./genai/lib/python3.12/site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in ./genai/lib/python3.12/site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./genai/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./genai/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in ./genai/lib/python3.12/site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install langgraph azure-ai-inference pinecone mlflow pydantic\n",
    "!python3 -m pip install langchain_openai\n",
    "!python3 -m pip install pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c99266",
   "metadata": {},
   "source": [
    "## 2. Load KB Data\n",
    "Load the KB JSON file and inspect its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "616fcb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc_id': 'KB001', 'question': 'What are best practices for debugging?', 'answer_snippet': \"When addressing debugging, it's important to follow well-defined patterns...\", 'source': 'debugging_guide.md', 'confidence_indicator': 'moderate', 'last_updated': '2024-01-10'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load KB data from JSON file\n",
    "with open(\"self_critique_loop_dataset.json\", \"r\") as f:\n",
    "    kb_data = json.load(f)\n",
    "\n",
    "# Display sample entry\n",
    "print(kb_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e2765d",
   "metadata": {},
   "source": [
    "## 3. Generate Embeddings using Azure OpenAI\n",
    "Use Azure's `text-embedding-3-small` model to generate embeddings for each KB entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91c573af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 30 embeddings.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import os\n",
    "load_dotenv()\n",
    "# Optional: kill legacy envs that cause the validation error\n",
    "\n",
    "for bad in (\"OPENAI_API_BASE\", \"OPENAI_API_TYPE\"):\n",
    "    os.environ.pop(bad, None)\n",
    "\n",
    "# client = OpenAIClient(endpoint=endpoint, credential=AzureKeyCredential(api_key))\n",
    "\n",
    "# Generate embeddings for answer_snippet\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    # You can rely on env vars instead; passing explicitly is fine too:\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    openai_api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-02-01\"),\n",
    "\n",
    "    # Use your Azure **deployment name** for the embeddings model\n",
    "    model=\"text-embedding-3-small\",    # <-- your deployment name\n",
    "    # dimensions=3072  # optional if you configured custom dims on text-embedding-3*\n",
    ")\n",
    "\n",
    "\n",
    "kb_embeddings = []\n",
    "\n",
    "\n",
    "for entry in kb_data:\n",
    "    text = entry[\"answer_snippet\"]\n",
    "    embedding = embedding_model.embed_query(text)\n",
    "    kb_embeddings.append({\n",
    "        \"id\": entry[\"doc_id\"],\n",
    "        \"embedding\": embedding,\n",
    "        \"metadata\": entry\n",
    "    })\n",
    "\n",
    "print(f\"Generated {len(kb_embeddings)} embeddings.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284efd95",
   "metadata": {},
   "source": [
    "## 4. Index into Pinecone\n",
    "Store the generated embeddings into Pinecone trial cloud instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a958a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zadmin/Desktop/GAAI-B4-Azure/genai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted 30 vectors into Pinecone.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "import certifi\n",
    "import os\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "# Define index name and embedding dimension\n",
    "index_name = \"agentic-rag-index\"\n",
    "dimension = len(kb_embeddings[0][\"embedding\"])\n",
    "\n",
    "# Create index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=dimension,\n",
    "        metric=\"cosine\",  # or \"euclidean\"\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",       # required even for trial\n",
    "            region=\"us-east-1\" # trial region\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Upsert embeddings\n",
    "vectors = [(item[\"id\"], item[\"embedding\"], item[\"metadata\"]) for item in kb_embeddings]\n",
    "index.upsert(vectors=vectors)\n",
    "\n",
    "print(f\"Upserted {len(vectors)} vectors into Pinecone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a1a52e",
   "metadata": {},
   "source": [
    "## 5. LangGraph Workflow\n",
    "Define nodes for Retriever, LLM Answer, Self-Critique, and Refinement using LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c30f209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some best practices for debugging:\n",
      "\n",
      "1. **Understand the Problem**: Clearly define the issue and gather as much information as possible about the symptoms and context.\n",
      "\n",
      "2. **Reproduce the Issue**: Try to consistently reproduce the bug to understand its conditions and behavior.\n",
      "\n",
      "3. **Check Logs and Error Messages**: Review logs, error messages, and stack traces for clues about what went wrong.\n",
      "\n",
      "4. **Isolate the Code**: Narrow down the code section where the bug occurs. Use techniques like commenting out sections or using breakpoints.\n",
      "\n",
      "5. **Use a Debugger**: Utilize debugging tools to step through the code, inspect variables, and monitor the flow of execution.\n",
      "\n",
      "6. **Add Logging**: Insert logging statements to track variable values and program flow, especially in complex areas.\n",
      "\n",
      "7. **Simplify the Problem**: Reduce the complexity of the code to isolate the bug, if possible.\n",
      "\n",
      "8. **Check for Common Issues**: Look for common pitfalls such as off-by-one errors, null references, or incorrect data types.\n",
      "\n",
      "9. **Consult Documentation**: Refer to relevant documentation for libraries, frameworks, or languages being used.\n",
      "\n",
      "10. **Seek Help**: If stuck, ask for help from colleagues or online communities, providing clear details about the issue.\n",
      "\n",
      "11. **Test Fixes**: After making changes, thoroughly test to ensure the bug is resolved and no new issues are introduced.\n",
      "\n",
      "12. **Document the Process**: Keep notes on what was tried, what worked, and what didn’t for future reference.\n",
      "\n",
      "By following these practices, you can improve your debugging efficiency and effectiveness.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# RAG with LangGraph + Azure OpenAI\n",
    "# -----------------------------\n",
    "import os\n",
    "from typing import List, Optional, TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "\n",
    "\n",
    "# --- Configure Azure OpenAI ---\n",
    "# Ensure these env vars are set:\n",
    "# AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_API_KEY, AZURE_OPENAI_API_VERSION\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt4o\",  # or \"gpt-4-mini\"\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    openai_api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-02-01\"),\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "embeddings = embedding_model\n",
    "\n",
    "# --- Define State ---\n",
    "class RAGState(TypedDict, total=False):\n",
    "    query: str\n",
    "    query_embedding: List[float]\n",
    "    retrieved: List[dict]  # [{'id': str, 'metadata': {...}, 'score': float, ...}, ...]\n",
    "    initial_answer: str\n",
    "    critique: str          # \"COMPLETE\" or \"REFINE\"\n",
    "    final_answer: str\n",
    "\n",
    "\n",
    "# --- Plug in your retriever / vector index here ---\n",
    "# Expectation: index.query(vector: List[float], top_k: int, include_metadata: bool)\n",
    "# returns an object with .matches -> list of objects each with:\n",
    "#   .id, .score, .metadata (with key \"answer_snippet\"), and .to_dict()\n",
    "#\n",
    "# Example placeholder interface:\n",
    "class _Match:\n",
    "    def __init__(self, _id, _metadata, _score=0.0):\n",
    "        self.id = _id\n",
    "        self.metadata = _metadata\n",
    "        self.score = _score\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\"id\": self.id, \"metadata\": self.metadata, \"score\": self.score}\n",
    "\n",
    "class _QueryResult:\n",
    "    def __init__(self, matches):\n",
    "        self.matches = matches\n",
    "\n",
    "class _Index:\n",
    "    def query(self, vector: List[float], top_k: int, include_metadata: bool = True):\n",
    "        # TODO: Replace with your actual vector DB call.\n",
    "        # For now, return empty to demonstrate guardrails.\n",
    "        return _QueryResult(matches=[])\n",
    "\n",
    "index = _Index()\n",
    "\n",
    "\n",
    "# --- Node functions ---\n",
    "def retrieve_snippets(state: RAGState) -> RAGState:\n",
    "    query_vec = state.get(\"query_embedding\", [])\n",
    "    response = index.query(vector=query_vec, top_k=5, include_metadata=True)\n",
    "    state[\"retrieved\"] = [m.to_dict() for m in response.matches]\n",
    "    return state\n",
    "\n",
    "\n",
    "def _build_context(snippets: List[dict]) -> str:\n",
    "    context_parts = []\n",
    "    for m in snippets or []:\n",
    "        mid = m.get(\"id\", \"unknown-id\")\n",
    "        md = m.get(\"metadata\", {}) or {}\n",
    "        snippet = md.get(\"answer_snippet\")\n",
    "        if snippet:\n",
    "            context_parts.append(f\"{snippet} [{mid}]\")\n",
    "    return \" \".join(context_parts).strip()\n",
    "\n",
    "\n",
    "def generate_answer(state: RAGState) -> RAGState:\n",
    "    query = state[\"query\"]\n",
    "    snippets = state.get(\"retrieved\", [])\n",
    "    context = _build_context(snippets)\n",
    "\n",
    "    if not context:\n",
    "        # Minimal fallback when retrieval is empty\n",
    "        prompt = (\n",
    "            \"The retrieval returned no helpful context. \"\n",
    "            f\"Provide a concise, generally accepted best-practices answer to:\\n\\n{query}\"\n",
    "        )\n",
    "    else:\n",
    "        prompt = f\"Answer the question using ONLY the following context.\\n\\nQuestion: {query}\\n\\nContext:\\n{context}\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    state[\"initial_answer\"] = (getattr(response, \"content\", None) or \"\").strip()\n",
    "    return state\n",
    "\n",
    "\n",
    "def self_critique(state: RAGState) -> RAGState:\n",
    "    answer = state.get(\"initial_answer\", \"\")\n",
    "    query = state[\"query\"]\n",
    "    snippets = state.get(\"retrieved\", [])\n",
    "    context = _build_context(snippets)\n",
    "\n",
    "    # Ask the model to decide if refinement is needed, with strict output.\n",
    "    critique_prompt = (\n",
    "        \"You are a rigorous reviewer. Determine if the answer fully addresses the question \"\n",
    "        \"given the available context.\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        f\"Context: {context or '[NO CONTEXT]'}\\n\\n\"\n",
    "        f\"Answer: {answer}\\n\\n\"\n",
    "        \"Respond with EXACTLY one word: COMPLETE or REFINE.\\n\"\n",
    "        \"Use REFINE if the answer is missing important points, lacks evidence from context, \"\n",
    "        \"or could be made more precise.\"\n",
    "    )\n",
    "    resp = llm.invoke(critique_prompt)\n",
    "    raw = (getattr(resp, \"content\", \"\") or \"\").strip().upper()\n",
    "    state[\"critique\"] = \"COMPLETE\" if \"COMPLETE\" in raw and \"REFINE\" not in raw else \"REFINE\"\n",
    "    return state\n",
    "\n",
    "\n",
    "def refine_answer(state: RAGState) -> RAGState:\n",
    "    # If COMPLETE, pass through\n",
    "    if state.get(\"critique\") == \"COMPLETE\":\n",
    "        state[\"final_answer\"] = state.get(\"initial_answer\", \"\")\n",
    "        return state\n",
    "\n",
    "    # Otherwise, try retrieving one more snippet (e.g., best match)\n",
    "    query_vec = state.get(\"query_embedding\", [])\n",
    "    resp = index.query(vector=query_vec, top_k=1, include_metadata=True)\n",
    "    extra = resp.matches[0].to_dict() if resp.matches else None\n",
    "\n",
    "    snippets = state.get(\"retrieved\", [])[:]\n",
    "    if extra:\n",
    "        snippets.append(extra)\n",
    "\n",
    "    context = _build_context(snippets)\n",
    "    query = state[\"query\"]\n",
    "    prompt = (\n",
    "        \"Refine and improve the answer using ONLY the following context. \"\n",
    "        \"Preserve factuality, add missing key points, and keep the writing concise.\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Current Answer:\\n{state.get('initial_answer', '')}\"\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    state[\"final_answer\"] = (getattr(response, \"content\", None) or \"\").strip()\n",
    "    return state\n",
    "\n",
    "\n",
    "# --- Build LangGraph ---\n",
    "graph = StateGraph(RAGState)\n",
    "graph.add_node(\"retrieve\", retrieve_snippets)\n",
    "graph.add_node(\"answer\", generate_answer)\n",
    "graph.add_node(\"critique\", self_critique)\n",
    "graph.add_node(\"refine\", refine_answer)\n",
    "\n",
    "graph.set_entry_point(\"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"answer\")\n",
    "graph.add_edge(\"answer\", \"critique\")\n",
    "graph.add_conditional_edges(\"critique\", lambda s: s[\"critique\"], {\n",
    "    \"COMPLETE\": END,\n",
    "    \"REFINE\": \"refine\",\n",
    "})\n",
    "graph.add_edge(\"refine\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# --- Run ---\n",
    "query = \"What are best practices for debugging?\"\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "state: RAGState = {\"query\": query, \"query_embedding\": query_embedding}\n",
    "result = app.invoke(state)\n",
    "\n",
    "# Prefer final_answer; fall back to initial_answer\n",
    "print(result.get(\"final_answer\") or result.get(\"initial_answer\") or \"No answer produced.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f753bc7c",
   "metadata": {},
   "source": [
    "## 6. MLflow Logging\n",
    "Log retrieved snippets, model outputs, critique results, and final answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab50121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"Agentic_RAG\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"query\", \"What are best practices for debugging?\")\n",
    "    mlflow.log_param(\"retrieved_docs\", [match[\"id\"] for match in result[\"retrieved\"]])\n",
    "    mlflow.log_param(\"critique\", result[\"critique\"])\n",
    "    mlflow.log_text(result[\"initial_answer\"], \"initial_answer.txt\")\n",
    "    mlflow.log_text(result[\"final_answer\"], \"final_answer.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df540c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
